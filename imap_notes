# IMAP COMMANDS
Status response codes (optional):
    ALERT:
        human readable text, that should be passed to the user
    BADCHARSET
        optionally followed by a parenthesized list of charsets.  A SEARCH
        failed because the given charset is not supported
    CAPABILITY
    PARSE:
        human readable error after trying to parse a message
    PERMANENTFLAGS:
        a list of flags that can be changed permananently (that is, that
        changes persist across sessions)
    READ-ONLY
        A mailbox is selected read-only
    READ-WRITE
    TRYCREATE
        An append or copy attempt is failing because the target mailbox does
        not exist
    UIDNEXT
        indicates the next unique identifier value
    UIDVALIDITY
        indicates the unique identifier validity value
    UNSEEN

OK [response code] human-readable text
  - if tagged, indicates successful completion of a command
  - if untagged, indicates information-only message

NO [response code] human-readable text
  - if tagged, indicates unsuccessful completion of a command
  - if untagged, indicates a warning-only message

BAD [response code] human-readable text
  - if tagged, indicates protocol-level error in client command
  - if untagged, indicates protocol-level error or server error, for which the
    associated client command cannot be determined.

PREAUTH [response code] human-readable text
  - always untagged, possible greeting, indicates no LOGIN is necessary

BYE [response code] human-readable text:
  - may occur as part of the normal logout process, or
  - as a panic shutdown announcement, or
  - as an announcement of an inactivity autologout, or
  - as a greeting, indicating the server is not willing to accept a connection
    from this client
  - In the normal logout case, a client should continue to process commands
    because it is possible the server has not finished processing all commands

(1 = command generates 1 response, * = command generates many responses)

1 CAPABILITY
* LIST (might be multiple)
* LSUB
1 STATUS
1 SEARCH
1 FLAGS (after SELECT or EXAMINE)

* EXISTS (SELECT, EXAMINE, or size change)
* RECENT (SELECT, EXAMINE, or size change)

* EXPUNGE
    Cannot be sent when no command is in progress nor while responding to a
    FEATCH, STORE, or SEARCH command, because client and server would enter a
    race condition where synchronization of message sequence numbers would be
    ambiguous.  If a UID command is in progress, EXPUNGE *can* be sent.

* VANISHED
    Follows the same rules as EXPUNGE except a VANISHED response MUST NOT be
    sent during a UID SEARCH command that contains message numbers in the
    search criteria

* FETCH
    can be response to a command or a unilateral server data (flag update)

Unilateral data:
    Bye
    untagged OK or NO
    exists (indicates new message in the selected mailbox, even after APPEND)
    recent (indicates new message, which is marked recent)
    expunge (indicates a message has been deleted)
    fetch (flag updates; nothing else is allowed to change in a message)

# parsing issue:

ALERT can be an atom.  So in bison's grammar it is impossible to distinguish
between between an ALERT or an atom, when atom might consist of a single ATOM.

Solutions:
  - add more states to scanner so that only specific keywords are passed at
    specific times
        I dislike this because it would complicate the scanner, and it would
        require a lot more states, and there would have to be synchronization
        between which states are possible in the grammar and in the scanner.
  - add an extra "mask-literal" step after the scanner, where illegal literals
    get turned into ATOMS or ASTR_ATOMS, according to the parser state
        This has the same synchronization problem but it does not complicate
        the scanner.  Also, this is a "whitelist" strategy, not a "blacklist"
        strategy, which should make this less error prone.

What about error handling and parser callbacks?
    Let's look at some different situations:
      - bug or NOMEM in parser code: result in closing the imap session
      - bug or NOMEM in a parser callback: result in closing the imap session
      - unallowed input in parser code: server responds BAD
      - unallowed action in parser callback: server responds NO or BAD

    Let's approach it from categories of error results:
      - Application-ending errors:
          - our listener socket got closed on us maybe?
          - out of sync between connection_cb() and uv_accept()
      - Session-ending errors:
          - Transient, don't notify the user:
              - out-of-memory errors
              - broken connections
          - Non-transient, notify the user:
              -
      - Respondable errors:
          - Invalid IMAP syntax
          -
functional programming to replace bison?

   non-reentrant plan:
    get_command:
        get_tag:
            get_command_name:
            switch(name):
                case FETCH: get_fetch
                ...

What about the reentrant version?
    swtich:
        get_command_mode:
            get_tag_mode
        get_tag_mode:
            scan(TAG, &more)
            if(!more):
                // advance buffer
                get_command_name(tag)
        get_command_name_mode:
            scan(COMMAND, &more)
            if(!more):
                // advance buffer
                switch(name):
                    case FETCH: get_fetch(tag, command)

    Hm.  It seems not undoable, but I think it would be really verbose, and on
    top of that, there's no way to get away from having to implement a stack
    of states.  Frankly, I'd really like to use Bison's implementation.

    Not to mention, the bison error handling seems so much better than anything
    I would want to have to implement.

# header dependencies
imap_scan is self-contained; it has token definitions and scan_mode_t
imap_parse.y calls needs to set parser->scan_mode

imap_expression needs the parser->keep and parser->error


# general DITM architecture for IMAP:

IMAP is not designed to be a request-response architecture but rather a fully
bidirectional pipeline of synchronization information.  Many server "responses"
are not strictly "responses" but rather synchronization info that might be sent
as a response to a client request or unilaterally.  Other "responses" truly are
responses and would have no meaning if sent unilaterally.

Responses which *must* be handled whether or not we requested them (also, it is
probably not worth handling them any other way):

  - Any untagged status response
  - EXISTS
  - RECENT
  - EXPUNGE
  - FETCH (in some cases)

Responses which make no sense if sent unilaterally:
  - Any tagged status response
  - LIST
  - LSUB
  - SEARCH
  - STATUS

Responses which could be treated either way:
  - CAPABILITY
  - SEARCH
  - FLAGS

Responses which permit an untagged EXPUNGE response:
  - anything other than FETCH, STORE, or SEARCH
  - that means UID FETCH, UID STORE, and UID SEARCH are fair game
  - if a client sends anything other than FETCH, STORE, or SEARCH, it must wait
    until that response is completed before sending any message with message
    sequence numbers in it
  - the standard doesn't say this, but I think a client doing only UID commands
    would still have to wait for every command completion, due to it not being
    safe to do things like UID FETCH on a non-existent UID.  From that
    perspective, if you want to do pipelineing you must use message sequence
    numbers instead of uids.  (update: I think maybe you just have to handle
    BAD responses from the UID FETCH command...)

    But the other untagged responses (FETCH, RECENT, EXISTS) are allowed at any
    time, as far as I can tell.

Therefore, our general architecture will be the following:

                Server                Client
     ________  connections  _______  connections  ________
    |        | <---------- |       | <---------- |        |
    |  MAIL  | <---------- | LOCAL | <---------- | EMAIL  |
    | SERVER | <---------- | STORE |             | CLIENT |
    |________|             |_______|             |________|

With the following details:
  - There is one "unselected" server connection per user, through which all
    LIST and LSUB requests are passed.
  - There is one "selected" server connection per opened LOCAL STORE mailbox.
    If multiple email clients are accessing the same LOCAL STORE's INBOX, only
    one server connection has INBOX "selected".
  - There is one server connection per user which selects the DITM_KEYS mailbox
    DITM uses this box directly and does not let email clients see the box via
    LIST or LSUB or let them SELECT it or CREATE it or anything like that.
  - When a client connection calls an IMAP command, DITM first checks that
    the corresponding server connection has brought the relevant part of the
    LOCAL STORE up-to-date, and then the response is generated locally, not
    bounced off of the mail server, like is generally the case with POP.
  - Exceptions to the "response generated locally" include the LIST, LSUB,
    and (under some circumstances) STATUS commands, as well as any commands
    which alter the server state such as CREATE, DELETE, SUBSCRIBE, and
    UNSUBSCRIBE.
  - There is also another special mailbox, with a user-facing name, perhaps
    "DITM Alerts", which exists only on the LOCAL STORE, through which DITM
    can communicate security alerts or critical failures or whatnot.

OH SHIT, this architecture will suffer from a host of incorrect corner cases.
    (See https://imapwiki.org/ImapTest/ServerStatus)

    In general, there would be issues where expunges could not be executed
    on behalf of one downwards connection without affecting another downwards
    connection, because with this strategy multiple downwards connections would
    share a single upwards connection.  The only solution would be to simulate
    expunges and deleted flags, and then push up deleted flags and expunges in
    a piecemeal way.  That would introduce a lot of complexity and a lot of
    in-memory state, which would result in loss of state on shutdown (or even
    more complexity to prevent that).

    The alternate solution is to just have one upwards connection per downwards
    connection (the original plan).  In 90% of cases, this is equally efficient
    because it seems like a rare usage case to have multiple client connections
    to a single mailbox.  Even in the case that two mail clients were
    downloading identical copies of every message, only one upwards connection
    would download each message, and the two mail clients would each be served
    the message bodies directly from the decrypted local store.

    This alternate solution sounds about 10x simpler.

    The thought that went into the old strategy is not useless though... it
    seems like it would be very relevant if I ever end up operating in some
    kind of "offline" mode (which I will attempt not to do just yet).

    But I am afraid that some of the message passing architecture dreamt up for
    things like serializing flag updates will be useless... the only sane thing
    to do is to pass all flag stores or fetches to the server and have the mail
    server be the single point of truth.

OH SHIT, this actually *is* possible with the UIDPLUS command!  So this leaves
us with two stragegies:
    This leaves us with two strategies:

      - The "passthru" strategy: we only hold a cache of downloaded/decrypted
        files; most commands are passed directly through to the host
        mailserver, except FETCH's which may be intercepted and SEARCHes,
        which will have to be fused from server info and our own info

      - The "subserver" strategy: we accumulate commands from the mail client
        and only pass the relevant things to the mail server.  (update): to
        do this properly, you would have to track a local version of modseq
        numbers (and maybe even uids).

    Passthru pros:
      - very clean and easy
      - ditm layer has very neat and well-defined role in the system

    Passthru cons:
      - less code reuse; there's no real opportunity to extract high-level
        functionality into an imap controller interface that could be used by
        sm_fetch and ditm
      - (update): unable to handle situations like hiding un-decryptable
        messages

    Subserver pros:
      - There's something beautiful about having the master stream updates to
        us and we stream them to a lower client.
      - The logic to stream updates from the mail server is identical between
        sm_fetch and ditm
      - There arises a concept of high-level control that isn't really possible
        with a passthru strategy
      - This strategy will potentially be more flexible when with different
        backends

    Subserver cons:
      - To support CONDRESTORE/QRESYNC, most commands would just have to be
        relayed to the mail server anyways, so your one upwards connection
        would mostly just be a serialized version of the Passthru case.
      - I don't know the easy and correct solution for handing things like
        STOREs on expunged messages with correct MODSEQ data.
      - On second thought, I think the proper solution is to maintain an
        indepentent modseq record, and offer that to mail clients.  That would
        be easy to guarantee correctness (except in uninstall/reinstall cases).
        That would also work very neatly with non-IMAP backends; as long as you
        can stream updates from whatever backend, you can serve semantically
        correct IMAP to them.

    Conclusion:
        Passthru sounds easy but seems too inflexible to be tenable.  I think
        it most likely would not work.  Subserver is more complex but higly
        flexible and will definitely work, as well as working nicely with
        non-imap backends.


# Socket / TLS / IMAP engines:

     (libuv)          (OpenSSL)                           (thread pool)
    ________          ________          ________           ___________
   |        | rawin  |        | decin  |        | imapin  |           |
   | SOCKET | -----> |  TLS   | -----> |  IMAP  | ------> |   IMAP    |
   | ENGINE | <----- | ENGINE | <----- | ENGINE | <------ | FUNCTIONS |
   |________| rawout |________| decout |________| imapout |___________|

Memory contexts:
    IMAP user context (ixu)
      - for each user who is connected, run an IDLE session for key updates
      - maintain a count of active connections, so we know when to disconnect
      - allocated when a new user is identified
      - cleaned up when the last of the user's sessions end
      - has list of keys

    IMAP session context: (ixs)
      - allocated by socket engine on connection, or key-related IDLE session
      - lists commands in flight
      - has rawin, rawout buffers (SSL memory buffer type)
      - has decin, decout (dstr_t type)

    IMAP command context: (ixc)
      - allocated by IMAP engine
      - tracks state of command / command-specific variables
      - has imapin, imapout buffers (dstr_t type)

Should the socket engine, the TLS engine, and the IMAP engine be separated?
    Pros:
      - Testability would be much better, as each section of the pipeline could
        be tested individually.
      - Nodes would be modular, and could potentially be strung together in
        different orders (for non-TLS connections, or a STARTTLS variety, for
        example)
    Cons:
      - each engine would need to be separated with a buffer pool, and some
        sort of event queue for passing messages, with checks for freezing
        inputs when a buffer pool is empty and callbacks for unfreezing it.
        There would be a small explosion of callback functions due to lots of
      - different situations arising (such as a allocate_before_accept()
        callback and a cleanup_after_failed_accept() callback, just in the
        libuv connection_cb function)
      - There's not a forseeable need for the improved modularity
      - Far greater complexity, primarily due to the distributed error handling
    Conclusion:
      - No, Socket Engine / TLS Engine / IMAP Engine should be one monolithic
        block, because the improved modularity wouldn't actually be useful and
        the improved testability argument is a wash compared to the massive
        increase in complexity.

buffer pool api
    bufp_init() : allocates memory and sets bufp_empty_cb and bufp_avail_cb
    bufp_get() : returns an available dstr_t*, or calls bufp_empty_cb with data
    bufp_release() : might call bufp_avail_cb with same data

Application write:
    Command lists its own PERCOM struct in the IMAP engine's queue
    IMAP engine takes PERCOM and does whatever conversion, writing to PERCLI
    IMAP engine lists PERCLI in TLS engine's queue
    TLS engine takes PERCLI and does encryption
    TLS engine lists PERCLI in libuv's queue
    Socket engine sends the packet when it can.

Read from socket: (don't know which PERCOM it goes to yet)
    Socket engine reads from a socket, puts data in PERCLI struct
    libuv puts PERCLI in TLS engine's queue, uv_read_stop()
    TLS engine takes PERCLI and does decryption, uv_read_start() and kick loop
    TLS engine puts PERCLI in IMAP Engine's queue
    IMAP Engine decides which PERCOM needs this data, decodes into that PERCOM
    Command handles the data that was read

cleaning of all resources:
    Our pipeline is bidirectional (unavoidable, since libuv and openssl require
    one thread to be in charge of reading and writing).  Therefore, our
    shutdown protol needs to be bidirectional as well, and no node shuts down
    until it has received a "quit" message in both directions:
                              ______
                     downin  |      | downout
                     ------> | some | ------>
                     <------ | node | <------
                      upout  |______|   upin

    One node's shutdown sequence:
      - recieve "quit" message from upstream, on "downin"
      - (downin queue now empty, since nothing more will be sent)
      - pass "quit" downstream, via "downout"
      - (downout queue gets emptied by next link in chain)
      - wait for "quit" to come back up from downstream, via "upin"
      - (upin queue now empty, downstream node has agreed to quit)
      - wait for all writes to be returned from upstream
      - pass "quit" back upstream via "upout"
      - (upout queue now empty, and we can shutdown)

    Overall sequence:
      - libuv node initiates shutdown
      - when libuv receives a "quit" again, that means everything else has
        down_ref()'ed all relevant contexts, and libuv only has to close
        sockets for any remaining contexts, down_ref() them, and exit the loop.

Cleaning up of one connection, at any time:
  - if you call uv_close, and free all associated contexts, you might have
    (for instance) a read callback in the middle of writing to one of those
    contexts.
  - So what you need to do is have each engine promise to ignore the contexts,
    and after each engine promises, then have a callback that frees the
    contexts:
      - socket engine stops reading, closes socket, (ongoing writes are
        cancelled),
      - TLS engine stops processing packets in either direction
      - IMAP stops procesing packets or dispatching functions
      - Wait for any ongoing IMAP functions to complete
      - The last-engine-to-forget could be the one that does the cleanup
      - Or there could be a separate cleaner-upper thread that handles that
    Or:
      - each engine could own the things that it reads from.  Actually, I don't
        think this would solve anything.  It would just suck.
    Or:
      - we could try and do the whole thing on one single thread, possibly with
        the IMAP functions still offloaded to a separate thread.  This might be
        less complex than the multi-engine setup I was thinking of.

Buffer Pools:
    Originally I thought I could use buffers in between nodes the way that I
    did it with POP; the producer always appends to the buffer and the
    consuming thread leaves unconsumed data in the buffer.

    buffer pools are necessary for overlapped IO, like using the Windows IOCP
    API.  That is, on the read side, the kernel needs access to a new read
    buffer *before* the application has a chance to use the read buffer that
    just got filled.  This is good for network throughput, because if the
    network is the slowest part of the system, the best thing you can do is
    make sure that the slowest part runs as fast as possible.  The write side
    is similar.

    Buffer pools are also necessary in between separate nodes of a pipeline.
    That is, if you have a thread pool handling IMAP functions, if you want to
    avoid gratuitous read-stop and read-start operations on the socket, you
    need a pool of buffers that the read pipeline can write to.

    However, what if you have a single, slow, read-heavy IMAP function (such
    as a large message decryption) in flight at the same time as a lot of fast,
    chatty IMAP functions?  The read socket behind the IMAP function could fill
    all of the read-side buffer pool with useless packets.

    Basically, a mechanism that freezes the input to a node is not good enough,
    you need to be able to freeze a whole pipeline upstream from a node, and
    intelligently and efficiently unfreeze it at a later time.  Also, my
    current model for unfreezing the sockets is a FIFO model, but you would
    need a different model for unfreezing specific sockets at will.

    Of course, if you went the select() route (meaning one thread for the whole
    application) then you would avoid all of this, because every read would be
    taken to completion and every write would be taken to completion, always,
    by the single thread.  The single threaded libuv solution would similary
    only require the read buffers and the write buffers, and one thread's slow
    reading would never affect another thread's read-side buffering because
    there would only be one thread.


    OK, I am starting to think that the amount of extra complexity for having
    a multi-threaded-capable event-loop-based function is not worth the extra
    performance gain.

    I think I will build off of libuv (or maybe even just select()??) and just
    write a completely single-threaded application.



Ok... well... shit.  I see that I need a better mechanism for freezing
write pipelines no matter what.  So here goes:


New and improved modular pipelining:

    (see engine.h)

Error handling in the pipeline:
    the node furthest from the network is the node most capable of gracefully
    handling errors, therefore errors should be passed in that direction, and
    not the other way (IE, along read paths and write_done paths, but not
    read_done paths or write paths).

    An example:
      - read error talking to server, but only IMAP engine knows how to send
        a useful message via the other socket to the email client
    A contrapositive example:
      - IMAP engine decides there is an inconsistency and wants to abandon the
        connections.  The libuv thread doesn't give a fuck what the error was.

New bugs:
    how exactly do I determine the "ideal" number of buffers in a pool?
        I'm sure that there is a per-processor number that would be fine, and
        that a per-connection would be too much (in the many-imap-sessions
        case), however, I don't know what that right number would be.  Or there
        might be a per-connection component to it, if you know that every
        connection is always going to have at least one buffer being written to
        in the kernel, for instance.

        Answer: by making buffers belong to engines and not to sessions, the
        answer is clearly a per-processor number; no number of extra sessions
        will make any engine of the pipeline capable of processing more events
        per second.

    Wait... if the socket is closed all of the buffers allocated for cancelled
    reads will be passed to the read callback, right?
        I dunno.  The documentation seems to say no but I don't see how else
        you would free allocated buffers.  Smells like a recipe for a memory
        leak.

    I would like to have a more modular interace between engines.  In
    particular, there's no way to build out a fully-functional, TLS-capable
    fake imap client without borrowing the socket engine and the TLS engine.
    So I am going to just go ahead and engineer it the *right* way, meaning
    that all of the engines operate entirely independent of each other.  This
    will clean up a few parts of the code, such as:

      - the enormous, unweildy imap session context struct
      - poor testability of individual parts
      - overly complicated header dependencies

Error handling during reads and writes:

    Principles of correct error handling:

      - Errors need to bubble to higher levels of the stack.  The IMAP engine
        knows how to tell the user there is a broken socket but the socket
        doesn't know shit about a broken IMAP session.
      - Errors are not allowed to skip layers.  Intermediate layers of the
        application should be capable to take corrective action, even if they
        normally just pass the error along.

    Note that errors from the read side of the pipeline are passed in the the
    READ step, but write errors are passed in the WRITE_DONE step.  As a
    result, there are some additional aspects we need to enforce on writes
    which happen automatically for reads:

      - Synchronous writes should be possible.  An application should be able
        to write, and not write again until it is sure that write succeeded.
      - Synchronous write should not be necessary.  An application capable of
        handling errors asynchronously should be able to write asynchronously.

    As a consequence of those requirements, it becomes possible to pipeline
    reads (each engine at each step can process it's data and pass that to the
    next engine) but writes must be stacked (layer A which receives a WRITE
    cannot respond with WRITE_DONE until *after* the layer below it passes back
    a WRITE_DONE):

        R = "read", D = "read done", W = "write", D = "write done"

    Engine | Timeline of read and write.  Read is pipelined, write is stacked
    -------+-----------------------------------------------------------------
    Socket | R                      D
    TLS    |   R D                W   D
    IMAP   |     R D            W       D
    ...    |       R D        W           D
    ...    |         R D    W               D

    Engine |  Correct error handling is maintained (E = "error")
    -------+----------------------------------------------------
    Socket | R                      E
    TLS    |   R D                W   E
    IMAP   |     R D            W       E
    ...    |       E D        W           E
    ...    |         E D    W               E

    In order to achieve the same processing parallelism, the write side has to
    contain many more buffers than the read side.  This requirement worsens the
    longer the pipe becomes.  See this table of equivalent-parallelism buffer
    counts:

                  number or bufs,   number of bufs,
        Engine:   pipeline case:    stack case:
        -------------------------------------------------
        socket:         0                 0
        TLS:            5                 5
        IMAP:           5                10
        EngineX:        5                15
        EngineY:        5                20

    Essentially, for the EngineY to saturate the entire pipe in the pipeline
    case, it would be able to write 20 times (the count of all buffers in all
    engines of the pipeline).  In the stacked case, that would require 20
    separate buffers at the EngineY level, 15 at the EngineY level, etc.

    The clear alternative to this strategy is to separate returning the write
    buffer from the error handling.  One easy way would be to allocate error
    messages on the heap when they are detected and pass them via a different
    channel.  However, I have gone through great lengths to avoid meta-error-
    handling, and I am not going to abandon that now.

    Another possibility would be to separate the write buffers and the write
    error checking.  We would still need more and more error checking elements
    as you went down the pipeline.  I think since we are realistically talking
    about less than a MB of memory this is really just a non-issue, and the
    stacked write buffers is acceptable.

References:
    The only thing that we count references for (right now) is a session.  A
    session primarily unifies a group of reads/writes as belonging to each
    other and stores data about them.  Each engine contributes its own
    self-contained child struct to a session, on which only it can operate.
    Since multiple engines might have references to the session at any time, a
    reference count is a natural solution.

    To keep things simple, we will consider that there are only mainly two
    kinds of references: references associated with an event_t (like a read or
    a write), and references associated with some engine specific data (like a
    socket that belongs to a session).  In the first case, session counting
    looks like this:

        EV_READ, EV_WRITE: upref session before passing event
        EV_READ_DONE: (carries no error) downref session after receiving event*
        EV_WRITE_DONE: (carries error) downref session after receiving event
        EV_QUIT_DOWN, EV_QUIT_UP: carries no session information

    (*The reason that EV_READ_DONE has session information is to enable the
    possibility of a per-session event limit.  For example, if at most two
    reads were allowed to be associated with a given session then you would
    need to know which session an EV_READ_DONE came from.  Otherwise it would
    make more sense to drop the session information before passing back the
    EV_READ_DONE event.)

    In the second case, for references associated with some engine specific
    data, a call to abort a session results in the session calling the
    engine-data-specific mechanism for freeing the engine data, which should
    eventually downref the session.  It may be a while before the session is
    downref'd, such as with the socket engine, where closing the loop_data
    triggers the event loop to close the socket on-thread, and then at a later
    time in a close_cb the reference finally gets downref'd.

References, continued:
    Now that we're in the imaildir_t development, we have lots more references.

    I'll use boxes to draw general thread boundaries around several objects:

## UPDATE: THIS IS OUT OF DATE, see "Multi-threaded architecture"
#    _____________
#   |             |
#   | imap_engine |-------------- imap_session_t
#   |_____________|                 _____|_____
#        |        \_____           |     |     |
#        |              |          | fetcher_t |
# imap_session_t   imap_session_t  |     |     |
#    ____|_____     ____|_____     |    up_t   |
#   |    |     |   |    |     |    |_____|_____|
#   | server_t |   | server_t |          |
#   |    |     |   |    |     |          |
#   |   dn_t   |   |   dn_t   |          |
#   |____|_____|   |____|_____|          |
#        |              |        ________|___
#        |              +-------|            |
#        |                      | imaildir_t |
#        +----------------------|____________|

    But the ownership structures are weird:
      - imap_sessions are owned by fetchers and servers
      - servers are all owned by a singleton server_mgr
      - in real life, there will be a user_t owns several fetchers/servers

      - dn_t and up_t are owned by the imaildir
      - the imaildir_t is owned by the singleton dirmgr

    Garbage collected languages separate the memory lifetime from the open/close
    cycle.  Is that even my problem?

    My current issues are:
      - When is it safe for the dn_t to unref the server_t?  Right now there's
        a mutex protection on imaildir->access->dns, so anybody who is going to
        use that list has to hold the mutex, and you can be sure that when you
        pull the dn out of the list nobody else will try to contact that
        server.

        Unless they are already using that dn_t.  The only thread who should
        be using the dn_t is the server_t's thread, so right now if the server
        closes the imaildir, the dn releases it's server, but if the dirmgr
        closes the imaildir (which could happen on any thread), the dn does
        not release the server until later, when the imaildir is being freed.

        I don't like the weird logic there, where the release (and free) can
        happen at two different times.

        the dn_t cannot release the server while:
          - the imaildir_t holds it in a list
          - the server_t might be in a call to the dn_t

        the dn_t cannot be freed while:
          - the imaildir_t holds it in a list
          - the server_t holds a reference to it at all

        you could:
          - let the imaildir_t's list be one ref
          - let the server_t's pointer be the second ref
          - write the finalizer of dn to release the server if it hasn't been
            released

        There's still the problem of "when does dn release its server in the
        case that the imaildir force-closes it?"

        This is just the classic problem of me not separating the finalizer
        from the closer, simple as that.  A ref count to free the dn_t at the
        right time would indeed help with the freeing problem, and putting a
        conditional release of the server in the finalizer of the dn_t is all
        that's needed.


Life of a per-session data struct:

    session_allocator() -- called from any thread
        The session is allocated.  All engine-specific getters (such as
        session_get_ssl_ctx() for the tls engine) are prepared and all engine
        data structs are zeroed before calling engine_data_start() for each
        engine data struct.  The reason for that is that so that each engine
        can lazily init its own engine data struct, as after the first
        engine_data_start() call events for this session can be passed at any
        time.  Each engine_data_start() can pass a SESSION_START message to
        its engine as needed, enabling on-thread initialization.

        There should be at least one engine which opens a standing reference to
        the session (otherwise there's not much point in having a session), so
        generally the session_allocator() starts the session with one reference
        but downrefs the session after each engine_data_start has been called.

    session_close() -- called from any thread
        Can be called anytime after session_allocator calls the first
        engine_data_start().  This will queue a SESSION_CLOSE event on each
        engine for that engine's session data, enable on-thread resource
        cleanup.

    SESSION_START event:
        This is like a reminder, in case no normal events come in, to trigger
        an engine to look at a session.  Things like starting TCP connections
        or starting TLS handshakes might only work with this trigger, though if
        any normal events for this session are received before this event,
        those events should trigger the engine data initialization and this
        event should be ignored.  Not all engine data init()s will generate a
        SESSION_START, but any pipeline should have at least one node which
        needs a SESSION_START event to guarantee correct behavior, because all
        sessions either need a connection accept()'ed or they need somebody to
        pass the first data packet.  Since those things likely have to happen
        on-thread, SESSION_START is the trigger required.

    SESSION_CLOSE event:
        Triggers an engine to mark the session as closed and to free all
        resources this engine's data struct.  After the last ref_down the
        whole session will be freed.  Normal events recieved after a
        SESSION_CLOSE should not be processed (since the engine doesn't have
        the state in memory required to process them anymore).

    normal events, associated with a session:
        guaranteed to come after the engine data was initialized with zeros,
        but *not* guaranteed to come before the SESSION_START event.  Also,
        it is possible to receive more normal events *after* a SESSION_CLOSE.

    Potential Gotcha:
        Right now, I don't have a solution to guarantee that SESSION_START
        doesn't triggers an eventual SESSION_CLOSE on a neighbor node before
        the SESSION_START is even passed to that same neighbor (for example, if
        a quick tlse_data_init() fails, calling session_close() which pushes
        a SESSION_CLOSE event to the IMAP engine before the session allocator
        can call imape_data_init() to push the SESSION_START).  That means
        that you could actually recieve SESSION_CLOSE *before* you get
        SESSION_START.  We should be careful to implement that correctly.

    Properties of certain calls in each engine:
        engine_data_start():
            Only called once, from off thread, in the session_alloc.  This
            function should only send a SESSION_START event to the engine
            thread (with a corresponding ref_up).
        engine_data_onthread_start():
            Called from on thread, the first time a packet is seen for the
            session.  It will often be after the SESSION_START packet.   The
            arguments which are needed from the session must use getters to
            avoid a race condition during initialization of multiple engines.
        engine_data_close():
            Called from off thread, the first time session_close() is called.
            session_close() guarantees it engine_data_close() will only be
            called once.  This function should only send a SESSION_CLOSE to
            the engine thread
        engine_data_onthread_close():
            Called from on thread, and must be robust to being called many
            times.  In particular, in error situations, the engine which calls
            session_close() will often immediately call its own
            engine_data_onthread_close() to ensure no more packets are handled
            for that engine.  Then later it will receive its SESSION_CLOSE
            message and call engine_data_onthread_close() again.

    Error handling during session initialization:
        How does the error get passed?
            It makes a lot of sense to pass it through SESSION_CLOSE, since
            there will already be a dedicated event for any engine that might
            need to see the error.
        Who needs to see the error?
            Probably just always hand it to the highest application layer
        How is the error handled?
            Errors from incoming connections are just logged; no other user
            session need to be bothered.  Errors from outgoing sessions should
            be handled by whatever thing asked for the session to be created.

Life of a session:
    Sessions can be started in one of two ways:
      - a connecting session is created when we are acting as the client
      - an accepting session is created when we are acting as the server

    Connecting session:
      - The allocation of the session will come from outside of the pipeline.
        Some thread will call a session_alloc_connect() and feed in the
        mgr_data field for the session_destroyed callback.
      - The loop engine will use a SESSION_START event to trigger trying to
        make a connection.  Any packets which the loop receives before making
        the connection are buffered up in preconnected writes and written upon
        making the connection.
      - The first packet in the pipeline will come from the tls engine.  The
        tls engine starts the handshake (client side starts) then the remote
        imap server will send its hello.
      - we may or may not know which user the connection belongs to.  If we do
        know we probably can expect that the credentials are valid, because the
        connection is one that we initiated.  Of course, we always have to
        handle either connection.

    Accepting session:
      - The connection_cb for the listening socket will make a callback which
        will allocate the session.


Important hooks:
  - msgs EXPUNGE or folder DELETE should check file permissions to make sure
    command will succeed later
  - we'll need some sort of transaction log to track pending file operations
    in case of powerdown, so on reboot pending expunges,etc. are completed
  - When a box is opened, the recent flags need to be grabbed and put in the
    view of the box, but removed from the underlying box
  - when a box is closed, that is a trigger to check for file-deleting any
    expunged messages
      - Actually, what should really happen is there should be a update_check()
        hook called in several instances.  One such moment is after CHECK
        command.  Also, after receiving certain commands but before responding
        to them, it is allowed to change the message counts.  Those commands
        are any command except (FETCH or STORE or SEARCH).
  - on_message_file_deletion, queue EXPUNGE response for other sessions
  - on_append, queue EXISTS resposne for other sessions
  - on_flag_change queue FETCH responses for other sessions
  - when generating EXISTS, RECENT, or FLAGS responses, the counts for each
    should be calculated at resposne time by comparisons of real data

Deletions:
    I don't like how deletions are looking right now.  I dislike how there is
    a per-message reference count, and how opening a mailbox could mean walking
    through a hashmap of 10,000 or more messages to add references, and the
    same process again to close the mailbox.

    It makes more sense for the imap user session (ixu) to keep track of
    deleted files, and with each deleted file, a list of sessions that may are
    viewing it.  When a session closes the box, that triggers a garbage
    collection of the deletion list, removing session references that the
    deletion depends on.

Updates:
    I feel similarly about calculating updates as I do about deletions.  There
    are scalability issues with the performance of calculating updates on large
    boxes.  The number of updates is likely quite small compared to the size of
    an inbox, and it makes sense to keep some sort of much smaller data
    structure around to push short lists of messages-with-updates for each
    session.

    So a imap session (ixs) would have to keep a running count of recents, and
    number of messages (for EXISTS).  Ok... that is pretty easy.

    # exists (indicates new message in the selected mailbox, even after APPEND)
    # recent (indicates new message, which is marked recent)
    # expunge (indicates a message has been deleted)
    # fetch (flag updates; nothing else is allowed to change in a message)

Message sequences:
    Message indicies are per-session, so should be stored in imap session (view
    of a mailbox), and not in the user session (the "real" mailbox).

    We need to be able to map UID->index numbers, (for generating EXPUNGE
    response after messages are deleted by UID, and also able to dereference
    messages by either index or by UID.  Storing a list of imsg_view pointers
    which point to imsg_view's in a hashmap seems valid, but removing a message
    is expensive (caveat: if message deletion is expensive, it's not the end
    of the world).

        deref msg from UID -> const time
            hashmap lookup
        deref msg from IDX -> const time
            just index into array
        get IDX from UID -> log(N) time (*see below)
            binary search of our sorted UID array
        get UID from IDX -> const time
            hashmap lookup
        delete message -> N time (memmove. *If you wanted to also update a lot
                                  of cached seq numbers in the imsg_view_t's
                                  you would make get-IDX-from-UID const time)


    However, I see that if we modify our self-balancing binary tree to keep
    per-node counts of child nodes, it would be possible to dereference either
    by UID or by index, and easily go from one to the other.

        deref msg from UID -> log(N) time (const time at cost of extra hashmap)
            either walk the binary tree or look up via hashmap
        deref msg from IDX -> log(N) time
        get IDX from UID -> log(N) time
        get UID from IDX -> log(N) time
        delete message -> log(N) time

    In order to optimize for both best-worst-case performance and general
    coolness, I'm choosing option 2: modify jsw_atree to support indexing.

    Update: upon revisiting this, the const time lookups of the first strategy
    are awfully attractive, especially now that I have done the fun part of the
    second strategy (adding indexing to the atree).  However, I think there's
    another layer of complexity that is not being addressed here, which is that
    the indices need to be generated on a per-view basis.  The following should
    also be considered:
      - the cost from the "real" mailbox storage to assigning per-view indices
      - when do we actually have to update the indices in the view?  EXPUNGE?
      - the cost of porting updates back to the "real" mailbox from the view

    Update: no, to make things simple and to get message sequences "for free"
    I'm just going to do jsw_atrees everywhere.  If you have 10,000 messages,
    a lookup in the atree is only 14 comparisons.

Message store thread safety:

    There's a lot of possible message states, but we will try to restrict the
    possible combinations by not allowing views to include messages which have
    not been downloaded.  This simplifies the number of states (avoid complex
    states like "deleted-by-one-but-downloading-for-another"), at the cost of
    not allowing download-on-request behavior.  That's ok though, since first
    we want to support the full IMAP spec, and we couldn't support SEARCH
    properly with download-on-request behavior.

    So a full table of possible message states and the resulting states might
    look like:

        STATE      | log status  | file status | msgs status | expunged status
        ----------------------------------------------------------------------
(up_t)  detected   | unfilled    | not present | unfilled    | not present
        downloaded | unfilled    | as /tmp/uid | unfilled    | not present
        decrypted  | unfilled    | as /tmp/xyz | unfilled    | not present
        ----------------------------------------------------------------------
        available  | filled      | as /cur/uid | filled      | not present
        expunged   | expunged    | as /cur/uid | expunged    | unpushed
          .removed | ...         | not present | not present | ...
          .pushed  | pushed      | ...         | ...         | pushed
        ----------------------------------------------------------------------
(dn_t)  appended   | not present | as /tmp/abc | not present | not present
        encrypted  | not present | as /tmp/xyz | not present | not present
        (after successful message submission, the next step is "available")

    Notes:
      - A message is in msgs and in expunged only after it has been expunged
        locally and while there are still views open which have not accepted
        the expunged message.
      - expunged.removed is not a formal state; it is just what happens when
        either all server accessors accept an expunge, or when we detect on
        startup that a file exists on the filesystem that has been expunged.
        In either case, the message will not longer be in msgs.
      - expunged.pushed indicates the expunge command was pushed upstream
      - Server accessors only ever see messages that are in the second block.
        This is accomplished by simply building views that don't include the
        unfilled messages.
      - A uid is never removed from the log, though it is often updated
      - A uid in the log, once expunged, must never be updated as if it were a
        normal message.  This affects STORE-after-EXPUNGE cases.
      - The available->expunged transition can be triggered by a VANISHED,
        a VANISHED (EARLIER) — since the distinction only affects the up_t —
        or an EXPUNGE coming from the server accessor.  Those should all call
        the same imaildir_t command, which can handled any associated effects.
      - It's not ok to expunge a message locally without pushing the change,
        but only because the downwards connection could be broken right after
        we expunge locally, and we would have to then keep the remote
        connection open until the changes were done propagating upwards.  It is
        better to force the expunge to be synchronous.
      - It's not OK to append a message locally until after the remote APPEND
        is complete, due to the above reason, but also due to factors like
        the mail server reserves the right to reject the APPEND on the basis of
        storage quotas or something like that.
      - nothing in /tmp is reused across restarts

    Startup cases:
      - log shows "unfilled" but file not present: download/decrypt message
      - log shows "filled" but file not present: delete from remote store
      - log shows "expunged" without ".pushed": push expunge upstream
      - log shows "expunged" but file still present: delete locally

    Difficulties:

      - How to handle complex multi-updates, such as a new message which has
        been accepted by some accessor, accepted and updated by another,
        accepted and updated differently by another, and accepted and deleted
        by a final one?
          - An easy thing to do is to have two jsw_atree's of messages; one for
            messages which exist on the filesystem (whether semantically
            expunged or not), where a message remains viewable until all server
            accessors have finished reading it.  The second jsw_atree contains
            only expunged messages.
          - With the above strategy, storing flags on yet-unaccepted expunged
            messages would work fine (as long as you left those changes
            in-memory and did not try to log them; you'd instead have to log
            a noop change for the resulting modseq, if you wanted to support
            CONDSTORE or QRESYNC).
          - It should be the responsibility of the imaildir_t to serialize all
            flag-setting and expunging requests, keeping each base's meta
            up-to-date, and deleting files when the expunge has been accepted
            by all accessors.
          - The above responsibility implies an imaildir_update() function

      - How would STORE'ing flags work?  The easy thing to do is to accept the
        flags locally, create a modseq event for it, calculate a submission to
        send upwards, then send it.  This would be vulnerable to client noise
        like:

          - we accept +\Seen, create a modseq, and alert all clients
          - we queue a STORE +\Seen command
          - we recieve a FETCH FLAGS \FLAGGED response, the result of some
            STORE +\FLAGGED command sent by some other client
          - we create a new modseq, and alert clients again
          - we receive the FETCH FLAGS \Seen \Flagged response, the result of
            our own STORE command
          - we create a new modseq, and alert clients yet again

        I think this is ok though, because at the end of the day we have the
        correct state.  These sorts of race conditions are inherent to multiple
        clients setting conflicting values, but realistically they are pretty
        rare corner cases... a human user is only going to set a flag on one
        imap client at a time.

      - How would STORE'ing flags work if we did not force it to be
        synchronous?  We would have to track the modseq_dn that we know to be
        in agreement with the mailserver, so that if we crashed and restored
        we could re-submit the STOREs that we had sent already.  But that would
        require us to store the actual STORE command (which may be a flag diff)
        that we sent alongside every modseq in the database, which sounds
        terrible.

        Well, that's not quite true; you could pretty easily just allow remote
        updates to be trampled in the rare case of a mid-STORE crash.  99% of
        users would never notice the incorrectness.  I think the real
        difficulty would be the need for persisting the connection after the
        mail client disconnected, so probably it's better to force the change
        to be synchronous.

      - If we make STORE'ing synchronous, then every server accessor would have
        to receive some sort of serial whenever it sends a STORE (probably the
        tag of the upwards STORE command) and it would have to wait for that
        serial to be returned before it could actually respond to its client.
        That seems much more doable.


IMAP bugs:
  - not all SEARCH keys are supported
  - syntax error messages are utterly useless

Multi-threaded architecture:
    There was a time that I seriously considered what was worth making
    multi-threaded and what was not worth it (see discussion in
    8097492ba:imap_engine.h and later in 47b287f5ca:imap_engine.h).  When I
    originally made that decision, it was largely due to me thinking it would
    be possible to interact with bison via callbacks rather than having a
    struct for every possible message type.  That assumption failed miserably.

    Now, there's this weird semi-actor-based, semi-lock-based system between
    the fetcher_t, the up_t, the server_t, the dn_t, and the imaildir_t.
    The up_t is supposed to do its work on the fetcher_t's thread, even though
    it's basically owned by the imaildir_t, and it is confusing as shit.  I
    can barely keep it straight.

    That said, it seems to be pretty correct.  It's just that it took me way
    too much time to come up with all of the details.

    Of interest is the ratio of occurances of uv_mutex* and uv_rwlock*:

        instances of    in total    in citm/sm_fetch/sm_serve/libimaildir
        -----------------------------------------------------------------
        uv_mutex*       247         190
        uv_rwlock*      74          74

    In other words, *all* of the multithreading complexity is in those files.

    What benefits are there from this multithreading complexity?
     1) you can do some processing concurrently
     2) you can reduce the number of reentrant state machines

    Regarding 1): I don't know if anything I do is more costly than the
    encryption/decryption.  I haven't profiled it to check.  There is only one
    or two places where that happens though, so it would be pretty easy for the
    crypto to happen on other threads (and handle the result as asynchronous
    events).

    Regarding 2): Most of the interfaces I have ended up being tied to async
    state machines anyway.  Let's do a tally of (a)sync vs (s)ynchronous calls:

        // imaildir.h
        struct maildir_conn_up_i {
    a       void (*cmd)(maildir_conn_up_i*, imap_cmd_t*);
    a       void (*selected)(maildir_conn_up_i*, const ie_st_resp_t*);
    a       void (*synced)(maildir_conn_up_i*);
    a       void (*unselected)(maildir_conn_up_i*);
     -      void (*failure)(maildir_conn_up_i*, derr_t);
     -      void (*release)(maildir_conn_up_i*);
        };
        struct maildir_up_i {
      s     derr_t (*resp)(maildir_up_i*, imap_resp_t*);
      s     bool (*synced)(maildir_up_i*);
      s     bool (*selected)(maildir_up_i*);
      s     derr_t (*unselect)(maildir_up_i*);
        };
        struct maildir_conn_dn_i {
    a       void (*resp)(maildir_conn_dn_i*, imap_resp_t*);
    a       void (*advance)(maildir_conn_dn_i*);
     -      void (*failure)(maildir_conn_dn_i*, derr_t);
     -      void (*release)(maildir_conn_dn_i*);
        };
        struct maildir_dn_i {
      s     derr_t (*cmd)(maildir_dn_i*, imap_cmd_t*);
      s     bool (*more_work)(maildir_dn_i*);
      s     derr_t (*do_work)(maildir_dn_i*);
        };

        // up.h
      s derr_t make_select(up_t *up, unsigned int uidvld, unsigned long our_himodseq,
                imap_cmd_t **cmd_out, up_cb_t **cb_out);
      s void up_send_cmd(up_t *up, imap_cmd_t *cmd, up_cb_t *up_cb);

        // dn.h
      s void dn_update(dn_t *dn, update_t *update);

        // fetcher.h
        struct fetcher_cb_i {
     -      void (*dying)(fetcher_cb_i*, derr_t error);
     -      void (*release)(fetcher_cb_i*);
    a       derr_t (*login_ready)(fetcher_cb_i*);
    a       derr_t (*login_succeeded)(fetcher_cb_i*);
    a       derr_t (*login_failed)(fetcher_cb_i*);
    a       derr_t (*passthru_resp)(fetcher_cb_i*, passthru_resp_t *passthru_resp);
    a       derr_t (*select_succeeded)(fetcher_cb_i*);
    a       derr_t (*select_failed)(fetcher_cb_i*, const ie_st_resp_t *st_resp);
        };

    a   derr_t fetcher_login(fetcher_t *fetcher, const ie_dstr_t *user, const ie_dstr_t *pass);
    a   void fetcher_set_dirmgr(fetcher_t *fetcher, dirmgr_t *dirmgr);
    a   derr_t fetcher_passthru_req(fetcher_t *fetcher, passthru_req_t *passthru_req);
    a   derr_t fetcher_select(fetcher_t *fetcher, const ie_mailbox_t *m);


        // server.h
        struct server_cb_i {
     -      void (*dying)(server_cb_i*, derr_t error);
     -      void (*release)(server_cb_i*);
    a       derr_t (*login)(server_cb_i*, const ie_dstr_t*, const ie_dstr_t*);
    a       derr_t (*passthru_req)(server_cb_i*, passthru_req_t *passthru_req);
    a       derr_t (*select)(server_cb_i*, const ie_mailbox_t *m);
        };
    a   derr_t server_allow_greeting(server_t *server);
    a   derr_t server_login_succeeded(server_t *server);
    a   derr_t server_login_failed(server_t *server);
    a   void server_set_dirmgr(server_t *server, dirmgr_t *dirmgr);
    a   derr_t server_passthru_resp(server_t *server, passthru_resp_t *passthru_resp);
    a   derr_t server_select_succeeded(server_t *server);
    a   derr_t server_select_failed(server_t *server, const ie_st_resp_t *st_resp);

        // sf_pair.h
        struct sf_pair_cb_i {
      s     derr_t (*set_owner)(sf_pair_cb_i*, sf_pair_t *sf_pair,
                    const dstr_t *name, const dstr_t *pass, void **owner);
     -      void (*dying)(sf_pair_cb_i*, sf_pair_t *sf_pair, derr_t error);
     -      void (*release)(sf_pair_cb_i*, sf_pair_t *sf_pair);
        };

        // user.h
        struct user_cb_i {
     -      void (*dying)(user_cb_i*, user_t *caller, derr_t error);
        };
      s void user_start(user_t *user);
      s void user_cancel(user_t *user);
      s void user_close(user_t *user, derr_t error);
      s void user_release(user_t *user);
      s derr_t user_add_sf_pair(user_t *user, sf_pair_t *sf_pair);
      s bool user_remove_sf_pair(user_t *user, sf_pair_t *sf_pair);

    OK, we got 17 synchronous calls, 26 async calls, and 9 dying/release calls.

    Pros and cons of switching to a single engine_t for all of this logic:
        pros:
          - the hardest parts of the system (imaildir) become way simpler
          - other tricky parts (dirmgr, user_pool/user) become trivial
          - parts which could become harder (async calls) are already done
          - I need to do something to fix imaildir_t and up_t anwyay
          - many email clients only sync on one connection anyway
          - less boilerplate (server.c, fetcher.c)
          - tests will likely be much easier to write

        cons:
          - lots more architecture churning
          - possibly less performant with some email clients

    Decision: I want stability and simplicity more than I want to bull-rush a
    solution.  I'll do this refactor now.

UPDATE: The refactor is done.  There are a few important points to this
        refactor:
  - The citm engine is always at the top of the callstack
  - All _close() calls on citme objects are synchronous
  - All calls between citme objects are asynchronous

    Why make all close() calls synchronous?
      - It is easy to check if objects are closed in the citm engine, or at
        the very first entrypoint to any call made by the citm engine.  That
        makes it easy to reason about what is closed when you are anywhere else
        in the call stack; you can just assume that nothing that you would
        touch is ever closed, or you would also have been closed already.

      - A complication of this strategy is that you can't call close() on
        anything at any place except at the very top of the callstack.  That's
        not so hard... you just have to throw errors and only catch them in one
        place.

      - imalidir_t has some odd behavior, where it might close its accessor any
        time it is called.  To make that as safe as possible, it will also
        throw E_IMAILDIR at the same time so that the accessor does not try to
        operate after being closed

    Why are all calls between citm objects asynchronous?
      - Avoid callback hell.  Break callback chains along object boundaries.

      - Contain errors within major objects; i.e. a fetcher failure should not
        pass its error through the sf_pair and to the server that requested
        some command.

        Why not have all entrypoints to objects return void and handle their
        own errors internally? You could also imagine that if the server made a
        call through to the fetcher, the entrypoint in the fetcher could catch
        the error and call fetcher_close().  However, if all close() calls are
        synchronous (which is highly desirable), then fetcher_close() will
        result in a server_close(), and when control returns to the server
        object, the server would have to check if it was closed or not.

        Or in other words, synchronous close() calls demand that errors are
        passed up the stack to the base of the event handler in all cases.

    How are async calls implemented?
      - Async calls look like:

            void thing_do_something(thing_t *thing, arg_t *arg);

        where it is assumed that *arg belongs to *thing after the call is made.
        Under the hood, *thing is storing *arg in some buffer it will check
        later and enqueuing a wake_event_t with the citm engine so that *thing
        will wake up some time later and see the stored *arg value.

    POST-REFACTOR SUMMARY:
        I think this refactor was an excellent idea.  It took much less time
        than I expected, and the code got a lot simpler in several places where
        it was already so complicated that I barely understood what I had
        wrote a couple of weeks ago.

        There are some details in libimaildir that still don't seem quite
        right.  Before, I was dreading updating them because of how complicated
        libimaildir had gotten, but now they should be pretty easy to resolve.

    TL;DR: new mutex counts:

        instances of    in total    in citm/libimaildir
        -----------------------------------------------
        uv_mutex*       61          0
        uv_rwlock*      0           0

How does APPEND work?
    APPEND is allowed without having to SELECT a mailbox.  The naieve way to
    implement that would be as a passthru command (without saving it locally),
    and then populate the local filesystem via an actual download from the
    mail server.  That would be very clean because APPEND generates the same
    exact messages regardless of whether or not you were the conncection that
    just APPENDED the message.  But it's also unacceptably inefficient.

    Desired traits of our APPEND implementation:
      - it should support the live connection APPEND
      - it should support the implicit filesystem APPEND
      - no race conditions if e.g. we start an APPEND to an unopened imaildir
        and the imaildir is opened after the fact
      - same behavior for APPEND to an opened or a closed imaildir_t
      - same behavior if actual APPEND passes over the same up_t which is the
        imaildir_t's primary up_t, or if it passes over a different one

    ## UPDATE: this was a bad idea
    # Idea:
    #   - imaildir_t supports an appender_t accessor, which is not associated
    #     with any connection
    #   - appender_t declares that an append attempt is in progress
    #       - imaildir_t tells its primary up_t not to download messages until
    #         the attempt finishes
    #   - appender_t later declares that an append attempt failed or succeeded
    #   - if it succeeded, the imaildir_t renames the temporary file into place
    #       - imaildir_t tells its primary up_t to not download the UID but to
    #         otherwise continue downloading messages

    # What happens if the imaildir_t closes (fails) mid-APPEND?
    #   - I guess if it is in an inconsistent state there's nothing you can do
    #   - worst case is you redownload a message that you could have copied on
    #     disk
    #   - an alternate strategy would be to store messages as reference-counted
    #     blobs, and when the append
    #   - it's not valid to write the message on file first, because we are not
    #     able to know the UID until after the APPEND is successful

    # What happens when the imaildir_t reopens mid-APPEND?
    #   - fuck this is getting hard

    # What happens if the APPEND fails?
    #   - easy, you just tell the imaildir that it failed

    # Why does the appender_t need to be an accessor?
    #   - you need to keep the imaildir_t open, because the downloading pause is
    #     purely an in-memory concept; if you put it on the filesystem then it
    #     would wrongly persist against

    Idea:
      - dirmgr_t keeps an in-memory map of mailbox names to upload-in-progress
        status
      - up_t will query the dirmgr before trying to download a message

    Yeah, this is the way to go for sure; the imaildir_t could fail and come
    back, or show up mid-APPEND, and it's all the same to us.

UID Mapping:
    Keep a local ordering of UIDs, with a mapping of local UIDs to remote UIDs.
    This relieves us of having to synchronize our local source of truth
    (modseq numbers) with the remote source of truth (uids).

    So where do we use uid_up vs uid_dn?  This is the plan:

      - msg_view_t's in the dn_t: sort by uid_dn, to make interacting with the
        maildir_t as easy as possible.  Each view should have an up_t as well
        so that it is easy for the dn_t to translate uid_dn to uid_up for the
        imaildir.  This will be nice because the only part of the system which
        would ever specify ranges of uid_dn's would be the mail client, which
        will be talking to the dn_t, which is the only part of the system that
        keeps a list of messages indexed by uid_dn.  The dn_t will therefore
        also be repsonsible for converting from uid_dn to uid_up for all
        communication.

      - message files in the maildir: UID is not part of the maildir naming
        spec, so we were already putting the uid_up into the custom unique
        delivery identifier.  No change necessary.

      - msg_t's in the imaildir_t: sort by uid_up, so that you can handle
        UNFILLED messages.  Messages are only assigned uid_dn when they become
        FILLED, so it is useful for the imaildir_t to deal with uid_up.  All
        messages and expunges have an uid_up, but not all messages have a
        uid_dn.

      - lmdb metadata log: key by uid_up, for the same reason as the imaildir_t

    A minor detail is that we also need to track a uidvld_dn as well, since in
    the case of a corrupted local store, we won't be able to reliably
    reconstruct the uids that we previously presented to the mail client.

SELECT/EXAMINE transitions
    We should choose SELECT for the up_t if any of the dn_t's connected via
    SELECT.  But if the only SELECT dn_t disconnects, the up_t should
    transition to EXAMINE for correctness.  Or if it reconnects, the up_t
    must transition back to SELECT.

    What has to be synchronized for us to correctly transition S->E?
      - the relay commands?  Are there write-only ones that we would have to
        land before the transition?  Or would the in-order-handling of imap
        commands mean that no special work would be required?
      - I think we would have to treat the S->E transition kind of like a CLOSE
        where the dn_t that triggers the transition does not get an OK response
        until after the S->E transition completes

    Note that the fetcher will always formally unregister and reregister its
    up_t; it's the simplest way for fetcher logic.  Those are the moments that
    the up_t is freed/reinitialized.  However, the actual SELECT command always
    comes from the imaildir_t, and a single lifetime of an up_t may have many
    S->E transitions.

    Interestingly, a dn_t has no need to handle S->E transitions, since the
    server_t is always aware of potential transitions an will just unregister
    and reregister the dn_t.

    The asymmetry is based on the fact that the fetcher_t provides the up_t but
    has limited control over what is passed through the up_t.  By contrast, the
    server is much more in control of what goes through the dn_t.

RENAME non-INBOX
  - apply some client-side validation
      - valid character strings
      - no '..' or '.' or such junk
  - disconnect + freeze the source mailbox name
  - disconnect + freeze the desination mailbox name
      - almost certainly does not exist, in practice
  - attempt to rename on the server
  - if successful:
      - delete destination mailbox if it exists
      - rename source mailbox directory to destination
      - release the freeze we took on the source and destination mailbox names
  - else:
      - release the freeze we took on the source and destination mailbox names

RENAME INBOX
  - not supported by dovecot, so we won't support it.

Parallelism in up.c
  - definitely no parallelism before bootstrap fetch
  - possibly allow parallelism for fetching content
      - having a chain of overlapping fetches would mean that you could have
        maximum throughput even while supporting preemption mid-fetch
      - this is definitely desirable
  - deleting is limited in its parallelizability by only having one variable
    for tracking uids_up_being_expunged.  I don't think this is really worth
    working around, I think deletions are already batched.
  - passthru commands could be run in parallel without issue
  - idle obviously supports no parallelization

  CONCLUSION
    the client is really simple; there's only five different input types

Using IDLE to receive live key updates via IMAP
  - I think we definitely want keys in the database
  - We also would like to have free polling for keys in the database via IDLE
  - We could write some daemon that synchronizes keys in the database with keys
    on file
  - The database already synchronizes across installations
  - The daemon could be pretty dumb then
  - Or, we could just do long polling.  That's looking better and better.
  - Well... long polling just means that we have to get good streaming updates
    to any of a gajillion clients.  If we only stream updates from the database
    to one sync service on each machine, that sounds way more managable.  And
    then IMAP already has mechanisms for good streaming to every client.
  - The sync daemon would not even have to bother with watching the filesystem
    for updates, because there's no reason to support deletions via IMAP.
    Users will always delete keys via the cli or webui.  Uni-direction
    synchronization is pretty doable for sure.
  - Those mailboxes should be read-only for imap clients
  - We will have to make sure to place the files in a way that dovecot likes.
    LMTP looks like the right answer.
  - We may have to disable dovecot synchronization of those mailboxes
  - How would deletions work though?  You can't push a deletion through LMTP
  - You could post a request for deletion and hope a client deletes it
    eventually, but that doesn't really offer prompt account cleanup, which I
    think is an important privacy feature
  - looks like doveadm is the tool for the job!

    Conclusion:
      - db insertion of a key will also insert a row into a syncable keys table
      - db insertion will do a no-fail attempt to wake up the sync service
      - sync service will wake up (either right then or periodically)
      - sync service will see entries in the table, pass them over lmtp, and
        then delete them from the database

Account lifetimes and microservice interactions:
    # sessions that need kicking
      - dovecot: ensure all imap/pop sessions are kicked (/var/run/dovecot/anvil owned by root)
      - apache: log all php sessions out (/var/lib/php/sessions/ owned by www-data)
      - postfix smtpd: ensure all smtp sessions are kicked
            (this doesn't seem to be possible at all)

    # Tricky issues:
      - postfix: ensure no mail is between the sql user lookup and the queue
          - We could fix this by routing mail by UIDs rather than by email;
            that way when the out-of-date mail arrives the UID can be detected
            as invalid.
          - We could do tls-termination before postfix, and use that to
            determined the logged-in user.  Then we could implement postfix
            kicking at that layer.  That would effectively eliminate this
            possibility
          - We could to tcp interception (not tls termination), and then have a
            mechanism for blocking until all existing connections have ended,
            and use that to infer that the user under deletion can't have any
            active smtp connections
      - dovecot: ensure no mail is between the queue and the filesystem
            Honestly, I would kind of doubt that this possibility even exists.
      - dovecot: ensure that replicator refreshes it's list of existing users
            I think if we can prevent incoming mail to the mailbox, this is
            pretty irrelevant.

    The following issues would all be resolved if we used UIDs to identify
    accounts rather than emails:
      - keyops; they could be delivered after deletion and nobody cares
      - postfix queue: they could be delivered and nobody cares
      - kicking php sessions; they would just cease to work
      - postfix smtpd (receiving mail): they could be delivered and nobody cares
      - the whole deleter service could be replaced by a chron job that deletes
        dangling mailboxes
      - dovecot replication could not cause any problems

    You'd probably stil want:
      - to kick dovecot sessions at some point

    In fact, the only synchronization problem that would persist is:
      - postfix smtpd (sending mail) could send on behalf of a
        previously-existing user.  But this problem is not nearly as severe I
        think; it's kind of inherent in smtp itself.

    Keysync process:
    # in an unrelated process:
      - insert (email, pubkey, add) into keyops
    # in keysync:
      - see ops in keyops

Questions about keysync:
    How do I make the __keybox__ read-only?
    How do I create the __keybox__ automatically?
    If I create the mailbox, will dovecot automatically index it?
    Wait... can I just write a custom command via a dovecot plugin?
        PROS:
          - fewer services to manage
          - no pollution of user mailbox names
          - no dual-source-of-truth
          - no worries about a direct-to-server imap session mucking with keys
        CONS:
          - more learning required
          - more unknowns unknowns
        Let's do it.
